<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <title>Vulkan in 30 minutes</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="">
    <meta name="author" content="baldurk">

		<!-- Latest compiled and minified CSS -->
		<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/css/bootstrap.min.css" integrity="sha384-1q8mTJOASx8j1Au+a5WDVnPi2lkFfwwEAa8hDDdjZlpLegxhjVME1fgjWPGmkzs7" crossorigin="anonymous">

		<!-- Optional theme -->
		<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/css/bootstrap-theme.min.css" integrity="sha384-fLW2N01lMqjakBkx3l/M9EahuwpSfeNvV63J5ezn3uZzapT0u7EYsXMjQV+0En5r" crossorigin="anonymous">

		<link href="prism.min.css" rel="stylesheet" />

		<style>
			body {
				padding-top: 50px;
			}
			.list-inline{display:block;}
			.list-inline li{display:inline-block;}
			.list-inline li:before{content:'\2022'; margin:0 4px;}
		</style>
  </head>

  <body>

		<nav class="navbar navbar-inverse navbar-fixed-top">
		<div class="container">
			<div class="navbar-header">
				<button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
					<span class="sr-only">Toggle navigation</span>
					<span class="icon-bar"></span>
					<span class="icon-bar"></span>
					<span class="icon-bar"></span>
				</button>
				<a class="navbar-brand" href="vulkan-in-30-minutes.html#">Vulkan in 30 minutes</a>
			</div>
			<div id="navbar" class="collapse navbar-collapse">
				<ul class="nav navbar-nav">
					<li><a href="https://renderdoc.org/">RenderDoc</a></li>
					<li><a href="https://www.khronos.org/vulkan">Khronos</a></li>
					<li><a href="http://lunarg.com/vulkan/">LunarG SDK</a></li>
					<li><a href="https://twitter.com/baldurk">Twitter</a></li>
					<li><a href="mailto:baldurk@baldurk.org">Email</a></li>
				</ul>
			</div><!--/.nav-collapse -->
		</div>
		</nav>

    <div class="container">

      <h1>Vulkan in 30 minutes</h1>
			<p><sub><i>30 minutes not actually guaranteed.</i></sub></p>
			<p>I've written this post with a specific target audience in mind, namely those who have a good grounding in existing APIs (e.g. D3D11 and GL) and understand the concepts of multithreading, staging resources, synchronisation and so on but want to know specifically how they are implemented in Vulkan. So we end up with a whirlwind tour of what the main Vulkan concepts look like.</p>
			<p>This isn't intended to be comprehensive (for that you should read the spec or a more in-depth tutorial), nor is it heavy in background or justification. Hopefully by the end of this you should be able to read specs or headers and have a sketched idea of how a simple Vulkan application is implemented, but you will need to do additional reading.</p>
			<p>Mostly, this is the document I wish had already been written when I first encountered Vulkan - so for the most part it is tuned to what I would have wanted to know. I'll reference the spec whenever you should do more reading to get a precise understanding, but you'll at least know what to look for.</p>
			<p>- <a href="https://twitter.com/baldurk">baldurk</a></p>

			<h2>General</h2>
			<p>At the end of the post I've included a heavily abbreviated pseudocode program showing the rough steps to a hello world triangle, to match up to the explanations.</p>
			<p>A few simple things that don't fit any of the other sections:</p>
			<ul>
				<li>Vulkan is a C API, i.e. free function entry points. This is the same as GL.</li>
				<li>The API is quite heavily typed - unlike GL. Each enum is separate, handles that are returned are opaque 64-bit handles so they are typed on 64-bit (not typed on 32-bit, although you can make them typed if you use C++).</li>
				<li>A lot of functions (most, even) take extensible structures as parameters instead of basic types.</li>
				<li><code>VkAllocationCallbacks *</code> is passed into creation/destruction functions that lets you pass custom malloc/free functions for CPU memory. For more details read the spec, in simple applications you can just pass <code>NULL</code> and let the implementation do its own CPU-side allocation.</li>
			</ul>
			<div class="alert alert-warning" role="alert">
				<p>
					Warning: I'm not considering any error handling, nor do I talk much about querying for implementation limits and respecting them. While I'm not intentionally getting anything outright wrong, I am skipping over <em>many</em> details that a real application needs to respect. This post is just to get a grasp of the API, it's not a tutorial!
				</p>
			</div>

			<h2>First steps</h2>
			<p>You initialise Vulkan by creating an instance (<code>VkInstance</code>). The instance is an entirely isolated silo of Vulkan - instances do not know about each other in any way. At this point you specify some simple information including which layers and extensions you want to activate - there are query functions that let you enumerate what layers and extensions are available.</p>
			<p>With a <code>VkInstance</code>, you can now examine the GPUs available. A given Vulkan implementation might not be running on a GPU, but let's keep things simple. Each GPU gives you a handle - <code>VkPhysicalDevice</code>. You can query the GPUs names, properties, capabilities, etc. For example see <code>vkGetPhysicalDeviceProperties</code> and <code>vkGetPhysicalDeviceFeatures</code>.</p>
			<p>With a VkPhysicalDevice, you can create a <code>VkDevice</code>. The <code>VkDevice</code> is your main handle and it represents a logical connection - i.e. 'I am running Vulkan on this GPU'. <code>VkDevice</code> is used for pretty much everything else. This is the equivalent of a GL context or D3D11 device.</p>
			<div class="alert alert-info" role="alert">
				<p>N.B. Each of these is a 1:many relationship. A <code>VkInstance</code> can have many <code>VkPhysicalDevices</code>, a <code>VkPhysicalDevice</code> can have many <code>VkDevices</code>. In Vulkan 1.0, there is no cross-GPU activity, but you can bet this will come in the future though.</p>
			</div>
			<p>I'm hand waving some book-keeping details, Vulkan in general is quite lengthy in setup due to its explicit nature and this is a summary not an implementation guide. The overall picture is that your initialisation mostly looks like <code>vkCreateInstance()</code> &rarr; <code>vkEnumeratePhysicalDevices()</code> &rarr; <code>vkCreateDevice()</code>. For a quick and dirty hello world triangle program, you can do just that and pick the first physical device, then come back to it once you want error reporting &amp; validation, enabling optional device features, etc.</p>

			<h2>Images and Buffers</h2>
			<p>Now that we have a <code>VkDevice</code> we can start creating pretty much every other resource type (a few have further dependencies on other objects), for example <code>VkImage</code> and <code>VkBuffer</code>.</p>
			<p>For GL people, one kind of new concept is that you must declare at creation time how an image will be used. You provide a bit field, with each bit indicating a certain type of usage - color attachment, or sampled image in shader, or image load/store, etc.</p>
			<p>You also specify the tiling for the image - <code>LINEAR</code> or <code>OPTIMAL</code>. This specifies the tiling/swizzling layout for the image data in memory. <code>OPTIMAL</code> tiled images are opaquely tiled, <code>LINEAR</code> are laid out just as you expect. This affects whether the image data is directly readable/writable, as well as format support - drivers report image support in terms of 'what image types are supported in <code>OPTIMAL</code> tiling, and what image types are supported in <code>LINEAR</code>'. Be prepared for <em>very</em> limited <code>LINEAR</code> support.</p>
			<p>Buffers are similar and more straightforward, you give them a size and a usage and that's about it.</p>
			<div class="alert alert-info" role="alert">
				<p>Images aren't used directly, so you will have to create a <code>VkImageView</code> - this is familiar to D3D11 people. Unlike GL texture views, image views are mandatory but are the same idea - a description of what array slices or mip levels are visible to wherever the image view is used, and optionally a different (but compatible) format (like aliasing a <code>UNORM</code> texture as <code>UINT</code>).</p>
				<p>Buffers are usually used directly as they're just a block of memory, but if you want to use them as a texel buffer in a shader, you need to provide a <code>VkBufferView</code>.</p>
			</div>

			<h2>Allocating GPU Memory</h2>
			<p>Those buffers and images can't be used immediately after creation as no memory has been allocated for them. This step is up to you.</p>
			<p>Available memory is exposed to applications by the <code>vkGetPhysicalDeviceMemoryProperties()</code>. It reports one or more memory <em>heaps</em> of given sizes, and one or more memory <em>types</em> with given properties. Each memory type comes from one heap - so a typical example for a discrete GPU on a PC would be two heaps - one for system RAM, and one for GPU RAM, and multiple memory types from each.</p>
			<p>The memory types have different properties. Some will be CPU visible or not, coherent between GPU and CPU access, cached or uncached, etc. You can find out all of these properties by querying from the physical device. This allows you to choose the memory type you want. E.g. staging resources will need to be in host visible memory, but your images you render to will want to be in device local memory for optimal use. However there is an additional restriction on memory selection that we'll get to in the next section.</p>
			<p>To allocate memory you call <code>vkAllocateMemory()</code> which requires your <code>VkDevice</code> handle and a description structure. The structure dictates which type of memory to allocate from which heap and how much to allocate, and returns a <code>VkDeviceMemory</code> handle.</p>
			<p>Host visible memory can be mapped for update - <code>vkMapMemory()</code>/<code>vkUnmapMemory()</code> are familiar functions. All maps are by definition persistent, and as long as you synchronise it's legal to have memory mapped while in use by the GPU.</p>
			<p>GL people will be familiar with the concept, but to explain for D3D11 people - the pointers returned by <code>vkMapMemory()</code> can be held and even written to by the CPU while the GPU is using them. These 'persistent' maps are perfectly valid as long as you obey the rules and make sure to synchronise access so that the CPU isn't writing to parts of the memory allocation that the GPU is using (see later).</p>
			<div class="alert alert-info" role="alert">
				<p>This is a little outside the scope of this guide but I'm going to mention it any chance I get - for the purposes of debugging, persistent maps of <em>non-coherent</em> memory with explicit region flushes will be much more efficient/fast than coherent memory. The reason being that for coherent memory the debugger must jump through hoops to detect and track changes, but the explicit flushes of non-coherent memory provide nice markup of modifications.</p>
				<p>In RenderDoc to help out with this, if you flush a memory region then the tool assumes you will flush for every write, and turns off the expensive hoop-jumping to track coherent memory. That way even if the only memory available is coherent, then you can get efficient debugging.</p>
			</div>

			<h2>Binding Memory</h2>
			<p>Each <code>VkBuffer</code> or <code>VkImage</code>, depending on its properties like usage flags and tiling mode (remember that one?) will report their memory requirements to you via <code>vkGetBufferMemoryRequirements</code> or <code>vkGetImageMemoryRequirements</code>.</p>
			<p>The reported size requirement will account for padding for alignment between mips, hidden meta-data, and anything else needed for the total allocation. The requirements also include a bitmask of the memory types that are compatible with this particular resource. The obvious restrictions kick in here: that <code>OPTIMAL</code> tiling color attachment image will report that only <code>DEVICE_LOCAL</code> memory types are compatible, and it will be invalid to try to bind some <code>HOST_VISIBLE</code> memory.</p>
			<p>The memory type requirements generally won't vary if you have the same kind of image or buffer. For example if you know that optimally tiled images can go in memory type 3, you can allocate all of them from the same place. You will only have to check the size and alignment requirements per-image. Read the spec for the exact guarantee here!</p>
			<div class="alert alert-info" role="alert">
				<p>Note the memory allocation is by no means 1:1. You can allocate a large amount of memory and as long as you obey the above restrictions you can place several images or buffers in it at different offsets. The requirements include an alignment if you are placing the resource at a non-zero offset. In fact you will definitely want to do this in any real application, as there are limits on the total number of allocations allowed.</p>
			<p>There is an additional alignment requirement <code>bufferImageGranularity</code> - a minimum separation required between memory used for a <code>VkImage</code> and memory used for a <code>VkBuffer</code> in the same <code>VkDeviceMemory</code>. Read the spec for more details, but this mostly boils down to an effective page size, and requirement that each page is only used for one type of resource.</p>
			</div>
			<p>Once you have the right memory type and size and alignment, you can bind it with <code>vkBindBufferMemory</code> or <code>vkBindImageMemory</code>. This binding is <strong>immutable</strong>, and must happen before you start using the buffer or image.</p>

			<h2>Command buffers and submission</h2>
			<p>Work is explicitly recorded to and submitted from a <code>VkCommandBuffer</code>.</p>
			<p>A <code>VkCommandBuffer</code> isn't created directly, it is allocated from a <code>VkCommandPool</code>. This allows for better threading behaviour since command buffers and command pools must be externally synchronised (see later). You can have a pool per thread and <code>vkAllocateCommandBuffers()</code>/<code>vkFreeCommandBuffers()</code> command buffers from it without heavy locking.</p>
			<p>Once you have a <code>VkCommandBuffer</code> you begin recording, issue all your GPU commands into it <em>*hand waving goes here*</em> and end recording.</p>
			<p>Command buffers are submitted to a <code>VkQueue</code>. The notion of queues are how work becomes serialised to be passed to the GPU. A <code>VkPhysicalDevice</code> (remember way back? The GPU handle) can report a number of <em>queue families</em> with different capabilities. e.g. a graphics queue family and a compute-only queue family. When you create your device you ask for a certain number of queues from each family, and then you can enumerate them from the device after creation with <code>vkGetDeviceQueue()</code>.</p>
			<p>I'm going to focus on having just a single do-everything <code>VkQueue</code> as the simple case, since multiple queues must be synchronised against each other as they can run out of order or in parallel to each other. Be aware that some implementations might require you to use a separate queue for swapchain presentation - I think chances are that most won't, but you have to account for this. Again, read the spec for details!</p>
			<p>You can <code>vkQueueSubmit()</code> several command buffers at once to the queue and they will be executed in turn. Nominally this defines the order of execution but remember that Vulkan has very specific ordering guarantees - mostly about what work can overlap rather than wholesale rearrangement - so take care to read the spec to make sure you synchronise everything correctly.</p>

			<h2>Shaders and Pipeline State Objects</h2>
			<p>The reasoning behind moving to monolithic PSOs is well trodden by now so I won't go over it.</p>
			<p>A Vulkan <code>VkPipeline</code> bakes in a lot of state, but allows specific parts of the fixed function pipeline to be set dynamically: Things like viewport, stencil masks and refs, blend constants, etc. A full list as ever is in the spec. When you call <code>vkCreateGraphicsPipelines()</code>, you choose which states will be dynamic, and the others are taken from values specified in the PSO creation info.</p>
			<p>You can optionally specify a <code>VkPipelineCache</code> at creation time. This allows you to compile a whole bunch of pipelines and then call <code>vkGetPipelineCacheData()</code> to save the blob of data to disk. Next time you can prepopulate the cache to save on PSO creation time. The expected caveats apply - there is versioning to be aware of so you can't load out of date or incorrect caches.</p>
			<p>Shaders are specified as SPIR-V. This has already been discussed much better elsewhere, so I will just say that you create a <code>VkShaderModule</code> from a SPIR-V module, which could contain several entry points, and at pipeline creation time you chose one particular entry point.</p>
			<p>The easiest way to get some SPIR-V for testing is with the reference compiler <a href="https://github.com/KhronosGroup/glslang">glslang</a>, but other front-ends are available, as well as LLVM &rarr; SPIR-V support.</p>

			<h2>Binding Model</h2>
			<p>To establish a point of reference, let's roughly outline D3D11's binding model. GL's is quite similar.</p>
			<ul>
				<li>Each shader stage has its own namespace, so pixel shader texture binding 0 is not vertex shader texture binding 0.</li>
				<li>Each resource <i>type</i> is namespaced apart, so constant buffer binding 0 is definitely not the same as texture binding 0.</li>
				<li>Resources are individually bound and unbound to slots (or at best in contiguous batches).</li>
			</ul>
			<p>In Vulkan, the base binding unit is a <em>descriptor</em>. A descriptor is an opaque representation that stores 'one bind'. This could be an image, a sampler, a uniform/constant buffer, etc. It could also be arrayed - so you can have an array of images that can be different sizes etc, as long as they are all 2D floating point images.</p>
			<p>Descriptors aren't bound individually, they are bound in blocks in a <code>VkDescriptorSet</code> which each have a particular <code>VkDescriptorSetLayout</code>. The <code>VkDescriptorSetLayout</code> describes the types of the individual bindings in each <code>VkDescriptorSet</code>.</p>
			<P>The easiest way I find to think about this is consider <code>VkDescriptorSetLayout</code> as being like a C struct type - it describes some members, each member having an opaque type (constant buffer, load/store image, etc). The <code>VkDescriptorSet</code> is a specific instance of that type - and each member in the <code>VkDescriptorSet</code> is a binding you can update with whichever resource you want it to contain.</p>
			<p>This is roughly how you create the objects too. You pass a list of the types, array sizes and bindings to Vulkan to create a <code>VkDescriptorSetLayout</code>, then you can allocate <code>VkDescriptorSets</code> with that layout from a <code>VkDescriptorPool</code>. The pool acts the same way as <code>VkCommandPool</code>, to let you allocate descriptors on different threads more efficiently by having a pool per thread.</p>
			<div class="panel panel-default">
				<div class="panel-body">
					<pre class="language-cpp"><code class="language-cpp">VkDescriptorSetLayoutBinding bindings[] = {
	// binding 0 is a UBO, array size 1, visible to all stages
	{ 0, VK_DESCRIPTOR_TYPE_UNIFORM_BUFFER, 1, VK_SHADER_STAGE_ALL_GRAPHICS, NULL },
	// binding 1 is a sampler, array size 1, visible to all stages
	{ 1, VK_DESCRIPTOR_TYPE_SAMPLER,        1, VK_SHADER_STAGE_ALL_GRAPHICS, NULL },
	// binding 5 is an image, array size 10, visible only to fragment shader
	{ 5, VK_DESCRIPTOR_TYPE_SAMPLED_IMAGE, 10, VK_SHADER_STAGE_FRAGMENT_BIT, NULL },
};
</code></pre>
				</div>
				<div class="panel-footer">Example C++ outlining creation of a descriptor set layout</div>
			</div>
			<p>Once you have a descriptor set, you can update it directly to put specific values in the bindings, and also copy between different descriptor sets.</p>
      <p>When creating a pipeline, you specify N <code>VkDescriptorSetLayouts</code> for use in a <code>VkPipelineLayout</code>. Then when binding, you have to bind matching <code>VkDescriptorSets</code> of those layouts. The sets can update and be bound at different frequencies, which allows grouping all resources by frequency of update.</p>
			<p>To extend the above analogy, this defines the pipeline as something like a function, and it can take some number of structs as arguments. When creating the pipeline you declare the types (<code>VkDescriptorSetLayouts</code>) of each argument, and when binding the pipeline you pass specific instances of those types (<code>VkDescriptorSets</code>).</p>
			<p>The other side of the equation is fairly simple - instead of having shader or type namespaced bindings in your shader code, each resource in the shader simply says which descriptor set and binding it pulls from. This matches the descriptor set layout you created.</p>
			<div class="panel panel-default">
				<div class="panel-body">
					<pre class="language-glsl"><code class="language-glsl">#version 430

layout(set = 0, binding = 0) uniform MyUniformBufferType {
// ...
} MyUniformBufferInstance;

// note in the C++ sample above, this is just a sampler - not a combined image+sampler
// as is typical in GL.
layout(set = 0, binding = 1) sampler MySampler;

layout(set = 0, binding = 5) uniform image2D MyImages[10];
</code></pre>
				</div>
				<div class="panel-footer">Example GLSL showing bindings</div>
			</div>

			<h2>Synchronisation</h2>
			<p>I'm going to hand wave a lot in this section because the specific things you need to synchronise get complicated and long-winded fast, and I'm just going to focus on what synchronisation is available and leave the details of <em>what</em> you need to synchronise to reading of specs or more in-depth documents.</p>
			<p>This is probably the hardest part of Vulkan to get right, especially since missing synchronisation might not necessarily break anything when you run it!</p>
			<p>Several types of objects must be 'externally synchronised'. In fact I've used that phrase before in this post. The meaning is basically that if you try to use the same <code>VkQueue</code> on two different threads, there's no internal locking so it will crash - it's up to you to 'externally synchronise' access to that <code>VkQueue</code>.</p>
			<p>For the exact requirements of what objects must be externally synchronised when you should check the spec, but as a rule you can use <code>VkDevice</code> for creation functions freely - it is locked for allocation sake - but things like recording and submitting commands must be synchronised.</p>
			<div class="alert alert-info" role="alert">
				<p>N.B. There is no explicit or implicit ref counting of any object - you can't destroy anything until you are sure it is never going to be used again by either the CPU or the GPU.</p>
			</div>
			<p>Vulkan has <code>VkEvent</code>, <code>VkSemaphore</code> and <code>VkFence</code> which can be used for efficient CPU-GPU and GPU-GPU synchronisation. They work as you expect so you can look up the precise use etc yourself, but there are no surprises here. Be careful that you do use synchronisation though, as there are few ordering guarantees in the spec itself.</p>
			<p>Pipeline barriers are a new concept, that are used in general terms for ensuring ordering of GPU-side operations where necessary, for example ensuring that results from one operation are complete before another operation starts, or that all work of one type finishes on a resource before it's used for work of another type.</p>
			<p>There are three types of barrier - <code>VkMemoryBarrier</code>, <code>VkBufferMemoryBarrier</code> and <code>VkImageMemoryBarrier</code>. A <code>VkMemoryBarrier</code> applies to memory globally, and the other two apply to specific resources (and subsections of those resources).</p>
			<p>The barrier takes a bit field of different memory access types to specify what operations on each side of the barrier should be synchronised against the other. A simple example of this would be "this <code>VkImageMemoryBarrier</code> has <code>srcAccessMask = ACCESS_COLOR_ATTACHMENT_WRITE</code> and <code>dstAccessMask = ACCESS_SHADER_READ</code>", which indicates that all color writes should finish before any shader reads begin - without this barrier in place, you could read stale data.</p>
			<h4>Image layouts</h4>
			<p>Image barriers have one additional property - images exist in states called <em>image layouts</em>. <code>VkImageMemoryBarrier</code> can specify a transition from one layout to another. The layout must match how the image is used at any time. There is a <code>GENERAL</code> layout which is legal to use for anything but might not be optimal, and there are optimal layouts for color attachment, depth attachment, shader sampling, etc.</p>
			<p>Images begin in either the <code>UNDEFINED</code> or <code>PREINITIALIZED</code> state (you can choose). The latter is useful for populating an image with data before use, as the <code>UNDEFINED</code> layout has undefined contents - a transition from <code>UNDEFINED</code> to <code>GENERAL</code> may lose the contents, but <code>PREINITIALIZED</code> to <code>GENERAL</code> won't. Neither initial layout is valid for use by the GPU, so at minimum after creation an image needs to be transitioned into some appropriate state.</p>
			<p>Usually you have to specify the previous and new layouts accurately, but it is always valid to transition from <code>UNDEFINED</code> to another layout. This basically means 'I don't care what the image was like before, throw it away and use it like this'.</p>

			<h2>Render passes</h2>
			<p>
			A <code>VkRenderpass</code> is Vulkan's way of more explicitly denoting how your rendering happens, rather than letting you render into then sample images at will. More information about how the frame is structured will aid everyone, but primarily this is to aid tile based renderers so that they have a direct notion of where rendering on a given target happens and what dependencies there are between passes, to avoid leaving tile memory as much as possible.
			</p>

			<div class="alert alert-info" role="alert">
				<p>
				N.B. Because I primarily work on desktops (and for brevity &amp; simplicity) I'm not mentioning a couple of optional things you can do that aren't commonly suited to desktop GPUs like input and transient attachments. As always, read the spec :).
				</p>
			</div>

			<p>
			The first building block is a <code>VkFramebuffer</code>, which is a set of <code>VkImageViews</code>. This is <strong>not</strong> necessarily the same as the classic idea of a framebuffer as the particular images you are rendering to at any given point, as it can contain potentially more images than you ever render to at once.
			</p>

			<p>
			A <code>VkRenderPass</code> consists of a series of <em>subpasses</em>. In your simple triangle case and possibly in many other cases, this will just be one subpass. For now, let's just consider that case.
			The subpass selects some of the framebuffer attachments as color attachments and maybe one as a depth-stencil attachment. If you have multiple subpasses, this is where you might have different subsets used in each subpass - sometimes as output and sometimes as input.</p>
			<p>Drawing commands can only happen inside a <code>VkRenderPass</code>, and some commands such as copies clears can only happen <b>outside</b> a <code>VkRenderPass</code>. Some commands such as state binding can happen inside or outside at will. Consult the spec to see which commands are which.</p>

			<p>
			Subpasses do not inherit state at all, so each time you start a <code>VkRenderPass</code> or move to a new subpass you have to bind/set all of the state.
			Subpasses also specify an action both for loading and storing each attachment. This allows you to say 'the depth should be cleared to 1.0, but the color can be initialised to garbage for all I care - I'm going to fully overwrite the screen in this pass'. Again, this can provide useful optimisation information that the driver no longer has to guess.
			</p>

			<p>The last consideration is compatibility between these different objects. When you create a <code>VkRenderPass</code> (and all of its subpasses) you don't reference anything else, but you do specify both the format and use of all attachments. Then when you create a <code>VkFramebuffer</code> you must choose a <code>VkRenderPass</code> that it will be used with. This doesn't have to be the exact instance that you will later use, but it does have to be compatible - the same number and format of attachments. Similarly when creating a <code>VkPipeline</code> you have to specify the <code>VkRenderPass</code> and subpass that it will be used with, again not having to be identical but required to be compatible.</p>

			<p>There are more complexities to consider if you have multiple subpasses within your render pass, as you have to declare barriers and dependencies between them, and annotate which attachments must be used for what. Again, if you're looking into that read the spec.</p>

			<h2>Backbuffers and presentation</h2>
			<p>I'm only going to talk about this fairly briefly because not only is it platform-specific but it's fairly straightforward.</p>
			<div class="alert alert-info" role="alert">
				<p>Note that Vulkan exposes native window system integration via extensions, so you will have to request them explicitly when you create your <code>VkInstance</code> and <code>VkDevice</code>.</p>
			</div>
			<p>To start with, you create a <code>VkSurfaceKHR</code> from whatever native windowing information is needed.</p>
			<p>Once you have a surface you can create a <code>VkSwapchainKHR</code> for that surface. You'll need to query for things like what formats are supported on that surface, how many backbuffers you can have in the chain, etc.</p>
			<p>You can then obtain the actual images in the <code>VkSwapchainKHR</code> via <code>vkGetSwapchainImagesKHR()</code>. These are normal <code>VkImage</code> handles, but you don't control their creation or memory binding - that's all done for you. You will have to create an <code>VkImageView</code> each though.</p>
			<p>When you want to render to one of the images in the swapchain, you can call <code>vkAcquireNextImageKHR()</code> that will return to you the index of the next image in the chain. You can render to it and then call <code>vkQueuePresentKHR()</code> with the same index to have it presented to the display.</p>
			<p>There are many more subtleties and details if you want to get really optimal use out of the swapchain, but for the dead-simple hello world case, the above suffices.</p>

			<h1>Conclusion</h1>

			<p>Hopefully you're still with me after that rather break-neck pace.</p>
			<p>As promised I've skipped a lot of details and skimmed over some complexities, for example I have completely failed to mention sparse resources support, primary and secondary command buffers, and I've probably missed some other cool things.</p>
			<p>With any luck though you have the broad-strokes impression of how a simple Vulkan applications is put together, and you're in a better place to go look at some documentation and figure the rest out for yourself.</p>
			<p>Any questions or comments, let me know on <a href="http://twitter.com/baldurk">twitter</a> or <a href="mailto:baldurk@baldurk.org">email</a>. In particular if anything is actually wrong I will correct it, as I don't want to mislead with this document - just set up a basic understanding that can be expanded on with further reading.</p>
			<p>Also just to plug myself a little, if you need a graphics debugger for Vulkan consider giving <a href="https://github.com/baldurk/renderdoc">RenderDoc</a> a try, and let me know if you have any problems.</p>
			<p>Happy hacking!</p>

			<h1>Appendix: Sample Pseudocode</h1>

			<pre class="language-cpp"><code class="language-cpp">#include &lt;vulkan/vulkan.h&gt;

// Pseudocode of what an application looks like. I've omitted most creation structures,
// almost all synchronisation and all error checking. This is not a copy-paste guide!
void DoVulkanRendering()
{
  const char *extensionNames[] = { "VK_KHR_surface", "VK_KHR_win32_surface" };

  // future structs will not be detailed, but this one is for illustration.
  // Application info is optional (you can specify application/engine name and version)
  // Note we activate the WSI instance extensions, provided by the ICD to
  // allow us to create a surface (win32 is an example, there's also xcb/xlib/etc)
  VkInstanceCreateInfo instanceCreateInfo = {
    VK_STRUCTURE_TYPE_INSTANCE_CREATE_INFO, // VkStructureType sType;
    NULL,                                   // const void* pNext;

    0,                                      // VkInstanceCreateFlags flags;

    NULL,                                   // const VkApplicationInfo* pApplicationInfo;

    0,                                      // uint32_t enabledLayerNameCount;
    NULL,                                   // const char* const* ppEnabledLayerNames;

    2,                                      // uint32_t enabledExtensionNameCount;
    extensionNames,                         // const char* const* ppEnabledExtensionNames;
  };

  VkInstance inst;
  vkCreateInstance(&amp;instanceCreateInfo, NULL, &amp;inst);

  // The enumeration pattern SHOULD be to call with last parameter NULL to
  // get the count, then call again to get the handles. For brevity, omitted
  VkPhysicalDevice phys[4]; uint32_t physCount = 4;
  vkEnumeratePhysicalDevices(inst, &amp;physCount, phys);

  VkDeviceCreateInfo deviceCreateInfo = {
    // I said I was going to start omitting things!
  };

  VkDevice dev;
  vkCreateDevice(phys[0], &amp;deviceCreateInfo, NULL, &amp;dev);

  // fetch vkCreateWin32SurfaceKHR extension function pointer via vkGetInstanceProcAddr
	VkWin32SurfaceCreateInfoKHR surfaceCreateInfo = {
		// HINSTANCE, HWND, etc
	};
  VkSurfaceKHR surf;
  vkCreateWin32SurfaceKHR(inst, &amp;surfaceCreateInfo, NULL, &amp;surf);

  VkSwapchainCreateInfoKHR swapCreateInfo = {
    // surf goes in here
  };
  VkSwapchainKHR swap;
  vkCreateSwapchainKHR(dev, &amp;swapCreateInfo, NULL, &amp;swap);

  // Again this should be properly enumerated
  VkImage images[4]; uint32_t swapCount;
  vkGetSwapchainImagesKHR(dev, swap, &amp;swapCount, images);

  // Synchronisation is needed here!
  uint32_t currentSwapImage;
  vkAcquireNextImageKHR(dev, swap, UINT64_MAX, presentCompleteSemaphore, NULL, &amp;currentSwapImage);

  // pass appropriate creation info to create view of image
  VkImageView backbufferView;
  vkCreateImageView(dev, &amp;backbufferViewCreateInfo, NULL, &amp;backbufferView);

  VkQueue queue;
  vkGetDeviceQueue(dev, 0, 0, &amp;queue);

  VkRenderPassCreateInfo renderpassCreateInfo = {
    // here you will specify the total list of attachments
    // (which in this case is just one, that's e.g. R8G8B8A8_UNORM)
    // as well as describe a single subpass, using that attachment
    // for color and with no depth-stencil attachment
  };

  VkRenderPass renderpass;
  vkCreateRenderPass(dev, &amp;renderpassCreateInfo, NULL, &amp;renderpass);

  VkFramebufferCreateInfo framebufferCreateInfo = {
    // include backbufferView here to render to, and renderpass to be
    // compatible with.
  };

  VkFramebuffer framebuffer;
  vkCreateFramebuffer(dev, &amp;framebufferCreateInfo, NULL, &amp;framebuffer);

  VkDescriptorSetLayoutCreateInfo descSetLayoutCreateInfo = {
    // whatever we want to match our shader. e.g. Binding 0 = UBO for a simple
    // case with just a vertex shader UBO with transform data.
  };

  VkDescriptorSetLayout descSetLayout;
  vkCreateDescriptorSetLayout(dev, &amp;descSetLayoutCreateInfo, NULL, &amp;descSetLayout);

  VkPipelineCreateInfo pipeLayoutCreateInfo = {
    // one descriptor set, with layout descSetLayout
  };

  VkPipelineLayout pipeLayout;
  vkCreatePipelineLayout(dev, &amp;pipeLayoutCreateInfo, NULL, &amp;pipeLayout);

  // upload the SPIR-V shaders
  VkShaderModule vertModule, fragModule;
  vkCreateShaderModule(dev, &amp;vertModuleInfoWithSPIRV, NULL, &amp;vertModule);
  vkCreateShaderModule(dev, &amp;fragModuleInfoWithSPIRV, NULL, &amp;fragModule);

  VkGraphicsPipelineCreateInfo pipeCreateInfo = {
    // there are a LOT of sub-structures under here to fully specify
    // the PSO state. It will reference vertModule, fragModule and pipeLayout
    // as well as renderpass for compatibility
  };

  VkPipeline pipeline;
  vkCreateGraphicsPipelines(dev, NULL, 1, &amp;pipeCreateInfo, NULL, &amp;pipeline);

  VkDescriptorPoolCreateInfo descPoolCreateInfo = {
    // the creation info states how many descriptor sets are in this pool
  };

  VkDescriptorPool descPool;
  vkCreateDescriptorPool(dev, &amp;descPoolCreateInfo, NULL, &amp;descPool);

  VkDescriptorSetAllocateInfo descAllocInfo = {
    // from pool descPool, with layout descSetLayout
  };

  VkDescriptorSet descSet;
  vkAllocateDescriptorSets(dev, &amp;descAllocInfo, &amp;descSet);

  VkBufferCreateInfo bufferCreateInfo = {
    // buffer for uniform usage, of appropriate size
  };

  VkMemoryAllocateInfo memAllocInfo = {
    // skipping querying for memory requirements. Let's assume the buffer
    // can be placed in host visible memory.
  };
  VkBuffer buffer;
  VkDeviceMemory memory;
  vkCreateBuffer(dev, &amp;bufferCreateInfo, NULL, &amp;buffer);
  vkAllocateMemory(dev, &amp;memAllocInfo, NULL, &amp;memory);
  vkBindBufferMemory(dev, buffer, memory, 0);

  void *data = NULL;
  vkMapMemory(dev, memory, 0, VK_WHOLE_SIZE, 0, &amp;data);
  // fill data pointer with lovely transform goodness
  vkUnmapMemory(dev, memory);

  VkWriteDescriptorSet descriptorWrite = {
    // write the details of our UBO buffer into binding 0
  };

  vkUpdateDescriptorSets(dev, 1, &amp;descriptorWrite, 0, NULL);

  // finally we can render something!
  // ...
  // Almost.

  VkCommandPoolCreateInfo commandPoolCreateInfo = {
    // nothing interesting
  };

  VkCommandPool commandPool;
  vkCreateCommandPool(dev, &amp;commandPoolCreateInfo, NULL, &amp;commandPool);

  VkCommandBufferAllocateInfo commandAllocInfo = {
    // allocate from commandPool
  };
  VkCommandBuffer cmd;
  vkAllocateCommandBuffers(dev, &amp;commandAllocInfo, &amp;cmd);

  // Now we can render!

  vkBeginCommandBuffer(cmd, &amp;cmdBeginInfo);
  vkCmdBeginRenderPass(cmd, &amp;renderpassBeginInfo, VK_SUBPASS_CONTENTS_INLINE);
  // bind the pipeline
  vkCmdBindPipeline(cmd, VK_PIPELINE_BIND_POINT_GRAPHICS, pipeline);
  // bind the descriptor set
  vkCmdBindDescriptorSets(cmd, VK_PIPELINE_BIND_POINT_GRAPHICS,
                          descSetLayout, 1, &amp;descSet, 0, NULL);
  // set the viewport
  vkCmdSetViewport(cmd, 1, &amp;viewport);
  // draw the triangle
  vkCmdDraw(cmd, 3, 1, 0, 0);
  vkCmdEndRenderPass(cmd);
  vkEndCommandBuffer(cmd);

  VkSubmitInfo submitInfo = {
    // this contains a reference to the above cmd to submit
  };

  vkQueueSubmit(queue, 1, &amp;submitInfo, NULL);

  // now we can present
  VkPresentInfoKHR presentInfo = {
    // swap and currentSwapImage are used here
  };
  vkQueuePresentKHR(queue, &amp;presentInfo);

  // Wait for everything to be done, and destroy objects
}
</code></pre>

    </div> <!-- /container -->

		<!-- Latest compiled and minified JavaScript -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.1/jquery.min.js"></script>
		<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/js/bootstrap.min.js" integrity="sha384-0mSbJDEHialfmuBBQP6A4Qrprq5OVfW37PRR3j5ELqxss1yVqOtnepnHVP9aJ7xS" crossorigin="anonymous"></script>

		<script src="prism.min.js"></script>
  </body>
</html>
